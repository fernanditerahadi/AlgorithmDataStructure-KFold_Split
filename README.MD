== KFold Cross Validation Test/Train Split Generator ==

This is a simple application to demonstrate partitioning a sample of data into complementary subsets
used in KFold Cross Validation.

(From Wikipedia.org) Cross-validation is a model validation technique for assessing how the results of a statistical
analysis will generalize to an independent data set. It is mainly used in settings where the goal is prediction,
and one wants to estimate how accurately a predictive model will perform in practice. In a prediction problem,
a model is usually given a dataset of known data on which training is run (training dataset), and a dataset of unknown
data (or first seen data) against which the model is tested. The goal of cross validation is to define a dataset to
"test" the model in the training phase (i.e., the validation set), in order to limit problems like overfitting,
give an insight on how the model will generalize to an independent dataset.

== Sample Result == 
![sample_result](https://github.com/vinsensiusfernandi/AlgorithmDataStructure-KFold_Split/blob/master/Sample%20Result/KFold.PNG)
